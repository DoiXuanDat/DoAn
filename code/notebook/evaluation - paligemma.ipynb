{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q -U \"transformers>=4.41.0\" \"datasets>=2.18.0\" \"accelerate>=0.28.0\" \"peft>=0.10.0\" \"bitsandbytes>=0.41.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_from_disk, Dataset\n",
    "from peft import PeftModel\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import (\n",
    "    PaliGemmaForConditionalGeneration,\n",
    "    PaliGemmaProcessor,\n",
    "    BitsAndBytesConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    if isinstance(image, np.ndarray):\n",
    "        if image.ndim == 2:\n",
    "            image = Image.fromarray(image, mode='L').convert('RGB')\n",
    "        elif image.ndim == 3 and image.shape[2] in [1, 3, 4]:\n",
    "            if image.shape[2] == 1:\n",
    "                image = Image.fromarray(image.squeeze(), mode='L').convert('RGB')\n",
    "            elif image.shape[2] == 3:\n",
    "                image = Image.fromarray(image, mode='RGB')\n",
    "            else:\n",
    "                image = Image.fromarray(image, mode='RGBA').convert('RGB')\n",
    "    elif isinstance(image, Image.Image):\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "    else:\n",
    "        raise ValueError(f\"Định dạng ảnh không được hỗ trợ: {type(image)}\") \n",
    "    return image\n",
    "\n",
    "def normalize_answer(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'\\b(a|an|the)\\b', ' ', s)\n",
    "    s = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]', '', s)\n",
    "    s = ' '.join(s.split())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def vqa_accuracy(predicted_answers, ground_truth_answers_list):\n",
    "\n",
    "    detailed_scores = []\n",
    "    for pred, gt_answers in zip(predicted_answers, ground_truth_answers_list):\n",
    "        pred_normalized = normalize_answer(pred)\n",
    "        answer_counts = Counter(normalize_answer(gt) for gt in gt_answers)\n",
    "        \n",
    "        score = 0.0\n",
    "        if pred_normalized in answer_counts:\n",
    "            score = min(answer_counts[pred_normalized] / 3.0, 1.0)\n",
    "        detailed_scores.append(score)\n",
    "        \n",
    "    accuracy = sum(detailed_scores) / len(detailed_scores) if detailed_scores else 0.0\n",
    "    return accuracy, detailed_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_path = \"/kaggle/input/vqa-v2/vqav2/dataset_arrow\" \n",
    "model_name = \"gintorikj/paligemma_vqav2_10pc\"\n",
    "base_model_id = \"google/paligemma-3b-pt-224\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds = load_from_disk(dataset_path)\n",
    "print(f\"Tổng số mẫu: {len(ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lấy một tập con để đánh giá\n",
    "eval_subset_size = 5000\n",
    "ds_eval = ds.select(range(min(eval_subset_size, len(ds))))\n",
    "print(f\"Sử dụng {len(ds_eval)} mẫu để đánh giá.\")\n",
    "\n",
    "def prepare_vqa_data(dataset):\n",
    "    processed_data = []\n",
    "    for item in dataset:\n",
    "        if 'answers' in item:\n",
    "            gt_answers = [ans['answer'] for ans in item['answers']]\n",
    "            processed_data.append({\n",
    "\n",
    "                'image': process_image(item['image']),\n",
    "                'question': item['question'],\n",
    "                'ground_truth_answers': gt_answers,\n",
    "            })\n",
    "    return processed_data\n",
    "\n",
    "processed_data = prepare_vqa_data(ds_eval)\n",
    "print(f\"Đã xử lý {len(processed_data)} mẫu có câu trả lời\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "base_model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "    base_model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0},\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "processor = PaliGemmaProcessor.from_pretrained(base_model_id)\n",
    "model = PeftModel.from_pretrained(base_model, model_name)\n",
    "model.eval()\n",
    "\n",
    "device = \"cuda:0\"\n",
    "eval_size = min(1000, len(processed_data))\n",
    "eval_data = processed_data[:eval_size]\n",
    "print(f\"Bắt đầu đánh giá trên {len(eval_data)} mẫu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "ground_truth_answers_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for item in tqdm(eval_data, desc=\"Đang đánh giá\"):\n",
    "        prompt = \"answer \" + item[\"question\"]\n",
    "        inputs = processor(\n",
    "            text=prompt,\n",
    "            images=item[\"image\"],\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        \n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=10, do_sample=False)\n",
    "        generated_text = processor.decode(generated_ids[0, inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n",
    "        predictions.append(generated_text)\n",
    "        ground_truth_answers_list.append(item[\"ground_truth_answers\"])\n",
    "\n",
    "\n",
    "vqa_acc, individual_scores = vqa_accuracy(predictions, ground_truth_answers_list)\n",
    "\n",
    "print(f\"KẾT QUẢ ĐÁNH GIÁ VQA\")\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Dataset: VQAv2\")\n",
    "print(f\"Số mẫu được đánh giá: {len(eval_data)}\")\n",
    "print(f\"VQA Accuracy: {vqa_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_examples = min(5, len(eval_data))\n",
    "random_indices = random.sample(range(len(eval_data)), num_examples)\n",
    "\n",
    "print(f\"\\nVí dụ dự đoán (hiển thị ảnh):\")\n",
    "for idx, i in enumerate(random_indices):\n",
    "\n",
    "    item = eval_data[i]\n",
    "    pred = predictions[i]\n",
    "    score = individual_scores[i]\n",
    "    gt_answers = ground_truth_answers_list[i]\n",
    "\n",
    "    plt.figure(figsize=(6, 6)) \n",
    "    plt.imshow(item['image'])\n",
    "    plt.title(f\"Câu hỏi: {item['question']}\\n\", fontsize=12)\n",
    "    plt.axis('off')  \n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Model dự đoán: {pred}\")\n",
    "    print(f\"Đáp án gốc (Ground Truth): {gt_answers}\")\n",
    "    print(f\"Điểm VQA cho câu này: {score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7592774,
     "sourceId": 12063864,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
